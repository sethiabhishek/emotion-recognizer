{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for loading data and images\n",
    "detection_model_path = 'models/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'models/_mini_XCEPTION.32-0.60.hdf5'\n",
    "img_path = 'first.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[382 170 513 513]\n",
      " [149 223  83  83]\n",
      " [206 606  61  61]]\n",
      "206 606 61 61\n",
      "[0.2902338  0.0003996  0.1220327  0.20010218 0.03656112 0.1834782\n",
      " 0.16719246]\n",
      "angry\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\",\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\"neutral\"]\n",
    " \n",
    "#reading the frame\n",
    "orig_frame = cv2.imread(img_path)\n",
    "frame = cv2.imread(img_path,0)\n",
    "faces = face_detection.detectMultiScale(frame,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "print(faces)\n",
    "if len(faces) > 0:\n",
    "    faces = sorted(faces, reverse=True,key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "    (fX, fY, fW, fH) = faces\n",
    "    print(fX,fY,fW,fH)\n",
    "    roi = frame[fY:fY + fH, fX:fX + fW]\n",
    "    roi = cv2.resize(roi, (48, 48))\n",
    "    roi = roi.astype(\"float\") / 255.0\n",
    "    roi = img_to_array(roi)\n",
    "    roi = np.expand_dims(roi, axis=0)\n",
    "    preds = emotion_classifier.predict(roi)[0]\n",
    "    print(preds)\n",
    "    emotion_probability = np.max(preds)\n",
    "    label = EMOTIONS[preds.argmax()]\n",
    "    print(label)\n",
    "#    cv2.putText(orig_frame, label, (fX, fY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "#    cv2.rectangle(orig_frame, (fX, fY), (fX + fW, fY + fH),(0, 0, 255), 2)\n",
    " \n",
    "#cv2.imshow('test_face', orig_frame)\n",
    "#cv2.imwrite('test_output/'+img_path.split('/')[-1],orig_frame)\n",
    "#if (cv2.waitKey(2000) & 0xFF == ord('q')):\n",
    "#    sys.exit(\"Thanks\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
